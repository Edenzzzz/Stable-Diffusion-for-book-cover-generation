{"cells":[{"cell_type":"markdown","metadata":{"id":"4Q_h9epMtVKw"},"source":["# ğŸŒŸData preprocessing for Stable Diffusion book cover generation trainingğŸŒŸ"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3195,"status":"ok","timestamp":1668962796727,"user":{"displayName":"Eden Tan","userId":"11491147198112718283"},"user_tz":360},"id":"rwI4ZieYtVKy","outputId":"410b59d2-6c1d-42ba-c6d3-ee34242a95b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import cv2,jpeg4py \n","import os\n","import matplotlib.pyplot as plt\n","try:\n","  from google.colab import drive\n","  drive.mount(\"/content/drive\",force_remount=True)\n","except:\n","  pass\n","# path='/Users/eden/Downloads/book dataset'\n","path=\"/content/drive/MyDrive/book dataset\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12172,"status":"ok","timestamp":1668963728855,"user":{"displayName":"Eden Tan","userId":"11491147198112718283"},"user_tz":360},"id":"4l3cluo1mQek","outputId":"8ee16d54-188b-47bb-d05a-c417434ccbb6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Testing df_train.csv\n","len(null_list):0,null_list=[]\n","------------------------------------------------------------------------------------------\n","Testing df_test.csv\n","len(null_list):0,null_list=[]\n","------------------------------------------------------------------------------------------\n"]}],"source":["#@title Test whether all test/train images can be read\n","import glob,os,pandas as pd\n","df_names=[\"df_train.csv\",\"df_test.csv\"]\n","for name in df_names:\n","  print(f\"Testing {name}\")\n","  df=pd.read_csv(f\"/content/drive/MyDrive/book dataset/{name}\")\n","  df.head() \n","  null_list=[] \n","  good_list=[]\n","  for index in df[df.columns[0]]:\n","    try:\n","      file=str(index)+\".jpg\"\n","      os.path.isfile(os.path.join(path+\"/images/images/\",file))\n","      good_list.append(file)\n","    except:\n","      null_list.append(file)\n","  print(f\"len(null_list):{len(null_list)},null_list={null_list}\")\n","  print(\"------------------------------------------------------------------------------------------\")\n"]},{"cell_type":"markdown","metadata":{"id":"WpIpcnsItVKy"},"source":["## 1.Finding a proper(mean) size to resize all images to.\n","I expect this to minimize quality loss due to resizing interpolation(bilinear, bicubic, etc.)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EdaHVWt1tVKz","outputId":"19105bce-7e7a-4916-8208-bccef9f73761"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-8edfa0eb5fa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msub_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mheights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mwidths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["heights=[]\n","widths=[]\n","#path of dataset on my local computer\n","img_path=path+\"/images/images\"\n","\n","df=pd.read_csv(os.path.join(path,\"book_data.csv\"))\n","num_failed=0\n","failed_indices=[]\n","num_images_before=len(df)\n","num_deleted=158\n","#\n","# import sys\n","# raw_stream=sys.stdout\n","# sys.stdout=open('opencv_error.txt','wb')\n","for index in range(len(df)):\n","    sub_path=os.path.join(img_path,str(index)+'.jpg')\n","    try:\n","        img=cv2.imread(sub_path)\n","        heights.append(img.shape[0])\n","        widths.append(img.shape[1])\n","    except AttributeError:\n","        failed_indices.append(index)\n","        df.drop(index,axis=0,inplace=True)\n","        num_failed+=1\n","# sys.stdout=raw_stream#restore\n","\n","print(\"Successfully read {} images\".format(len(heights)),\", failed to read {} images\".format(num_failed))\n","# print(f'Number of images before deleting failed images:{num_images_before}\\\n","#     \\nNumber of images after { len(os.listdir(img_path)) } ')\n","\n","\n","fig,axes=plt.subplots(1,2,figsize=(10,5))\n","\n","#plot 1\n","axes[0].set(xlabel='Height')\n","axes[0].hist(heights); axes[0].set(title='Distribution of image heights')\n","#draw vertical line\n","axes[0].axvline(np.mean(heights), color='orange', linestyle='dashed', linewidth=1)\n","axes[0].text(np.mean(heights)*1.1, axes[0].get_ylim()[1]*0.9, 'Mean: {:.2f}'.format(np.mean(heights)))\n","\n","#plot 2\n","axes[1].set(xlabel='Width')\n","axes[1].hist(widths); axes[1].set(title='Distribution of image widths')\n","axes[1].axvline(np.mean(widths), color='orange', linestyle='--', linewidth=1)\n","axes[1].text(np.mean(widths)*1.1, axes[1].get_ylim()[1]*0.9, 'Mean: {:.2f}'.format(np.mean(widths)))\n","plt.show()\n","\n","print(\"Failed images: \",failed_indices)"]},{"cell_type":"markdown","metadata":{"id":"Y-PYeUPgfUpE"},"source":["### Save data as numpy array for faster loading (will terminate the session at the end)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XkrsfiWRIdGr"},"outputs":[],"source":["# try:\n","#   from google.colab import runtime\n","#   import matplotlib.pyplot as plt\n","#   import tqdm\n","#   num_images_before=54301\n","#   size=256\n","#   stacked_images=np.zeros((num_images_before,size,size,3),dtype=\"float16\")#save memeory. The runtime crashes with float32\n","#   img_path=path+\"/images/images\"\n","\n","#   for index,file in enumerate(tqdm.tqdm(os.listdir(img_path))):\n","#     img=cv2.imread(os.path.join(img_path,file))\n","#     img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","#     img=cv2.resize(img,(size,size),interpolation=cv2.INTER_CUBIC).astype('float16')\n","#     if index%1000==0:\n","#       plt.title(str(index)+\" images processed!\")\n","#       plt.imshow(img.astype(\"int16\"))\n","#       # plt.show()\n","#     #this index has to correspond to the index in the csv file\n","#     try:\n","#       stacked_images[int(file.replace('.jpg','')),:,:,:]=img\n","#     except ValueError:\n","#       pass\n","      \n","#   np.save(os.path.join(path,\"stacked_images.npy\"),stacked_images)\n","#   assert os.path.isfile(os.path.join(path,\"stacked_images.npy\")), \"File not saved!\"\n","\n","#   runtime.unassign()#exit\n","# except:\n","#   pass"]},{"cell_type":"markdown","metadata":{"id":"_1VP23hRtVK0"},"source":["## 2. Preprocess text data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TVAKzu2tVK0"},"outputs":[],"source":["df=pd.read_csv(os.path.join(path,\"book_data.csv\"))\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"YA5e6M4TtVK0"},"source":["### 2.1 Remove entries whose corresponding image can't be read"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GUiVnj9gtVK1"},"outputs":[],"source":["len_before=len(df)\n","df.drop(failed_indices,inplace=True)\n","# df.drop(0,axis=0,inplace=True)\n","if len_before-len(failed_indices)==len(df):\n","    print(f\"Successfully dropped {len(failed_indices)} images!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QV-yy-HItVK1"},"outputs":[],"source":["#Only use 3 features \n","df=df[['book_authors',\"book_desc\",\"book_title\"]]\n","print(\"Number of NaN/None entries\\n:\",df.isna().sum(axis=0),\"\\n--------------------------------------\")\n","# print(\"First 3 null entries:\\n\",df[df['book_desc'].isnull()].iloc[:3])#isnull treats empty String as non-NaN.\n","df.dropna(axis=0,inplace=True)\n","print(\"Number of NaN/None entries after processing \\n \",df.isna().sum())\n","# print(df[df.isna()])#isna() is True for empty String''\n","# df.loc[94]\n","# df.head() "]},{"cell_type":"markdown","metadata":{"id":"0SioNJzntVK1"},"source":["### 2.2. Remove rows with non-English book description"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3JujC6y-tVK1"},"outputs":[],"source":["import re\n","non_English_sentence=\"34æ­³ç„¡è·ç«¥è²ã®ãƒ‹ãƒ¼ãƒˆã¯ç„¡ä¸€æ–‡ã§å®¶ã‚’è¿½ã„å‡ºã•ã‚Œã€è‡ªåˆ†ã®äººç”ŸãŒå®Œå…¨ã«è©°ã‚“ã§ã„ãŸã¨æ°—ä»˜ãã€‚å·±ã‚’å¾Œæ‚”ã—ã¦ã„ãŸçŸ¢å…ˆã€å½¼ã¯ãƒˆãƒ©ãƒƒã‚¯ã«è½¢ã‹ã‚Œå‘†æ°—ãªãæ­»ã‚“ã§ã—ã¾ã†ã€‚ã¤ã„ã§ç›®ã‚’è¦šã¾ã—ãŸå ´æ‰€ã¯â€•â€•ãªã‚“ã¨å‰£ã¨é­”æ³•ã®ç•°ä¸–ç•Œã ã£ãŸ!!ãƒ«ãƒ¼ãƒ‡ã‚¦ã‚¹ã¨åä»˜ã‘ã‚‰ã‚ŒãŸèµ¤ã‚“åŠã¨ã—ã¦ç”Ÿã¾ã‚Œå¤‰ã‚ã£ãŸå½¼ã¯ã€ã€Œä»Šåº¦ã“ãæœ¬æ°—ã§ç”Ÿãã¦è¡Œãã‚“ã â€¦â€¦ï¼ã€ã¨å¾Œæ‚”ã—ãªã„äººç”Ÿã‚’é€ã‚‹ã¨æ±ºæ„ã™ã‚‹ã€‚å‰ä¸–ã®çŸ¥èƒ½ã‚’æ´»ã‹ã—ãŸãƒ«ãƒ¼ãƒ‡ã‚¦ã‚¹ã¯ç¬ãé–“ã«é­”è¡“ã®æ‰èƒ½ã‚’é–‹èŠ±ã•ã›ã€å°ã•ãªå¥³ã®å­ã®å®¶åº­æ•™å¸«ã‚’ã¤ã‘ã¦ã‚‚ã‚‰ã†ã“ã¨ã«ã€‚ã•ã‚‰ã«ã¯ã‚¨ãƒ¡ãƒ©ãƒ«ãƒ‰ã‚°ãƒªãƒ¼ãƒ³ã®é«ªã‚’æŒã¤ç¾ã—ã„ã‚¯ã‚©ãƒ¼ã‚¿ãƒ¼ã‚¨ãƒ«ãƒ•ã¨ã®å‡ºä¼šã„ã€‚å½¼ã®æ–°ãŸãªäººç”ŸãŒå‹•ãå§‹ã‚ã‚‹ã€‚â€•â€•æ†§ã‚Œã®äººç”Ÿã‚„ã‚Šç›´ã—å‹è»¢ç”Ÿãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼ã€ã“ã“ã«å§‹å‹•ï¼\"\n","sentence=\"Despite the tumor-shrinking medical miracle that has bought her a few years, Hazel has never been anything but terminal, her final chapter inscribed upon diagnosis. But when a gorgeous plot twist named Augustus Waters suddenly appears at Cancer Kid Support Group, Hazel's story is about to be completely rewritten.Insightful, bold, irreverent, and raw, The Fault in Our Stars is award-winning author John Green's most ambitious and heartbreaking work yet, brilliantly exploring the funny, thrilling, and tragic business of being alive and in love.\"\n","filter=re.compile('[^A-Za-z0-9.,\\/#!$%\\^\\;:{}=\\-_`~()\\'\\\" ]*')\n","def remained_percent(sentence):\n","    \"\"\"Return how much percentage of the text is filtered out\n","    by the regex matching English words and punctuations\"\"\"\n","    sub=filter.sub(repl=\"\",string=sentence)\n","\n","    return len(sub)/len(sentence)\n","print(\"non-English:\",remained_percent(non_English_sentence))\n","print('English',remained_percent(sentence))\n","# re.sub(pattern=r\"\"\"<\\|startoftext\\|>|<\\|endoftext\\|>|'s|'t|'re|'ve|'m|'ll|'d|[\\p{L}]+|[\\p{N}]|[^\\s\\p{L}\\p{N}]+\"\"\",repl='',string=sentence)"]},{"cell_type":"markdown","metadata":{"id":"ZVuTdJvatVK2"},"source":["### 2.3 Drop non-English-like data points according to threshold and save two subsets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8yYnQKYftVK2"},"outputs":[],"source":["#Apply over the whole dataframe\n","drop_threshold=0.97\n","\n","df['percent_remained']=df['book_desc'].apply(remained_percent)\n","print(\"Mean percentage remained after applying filter:\",df['percent_remained'].mean())\n","dropped=df[df['percent_remained']<drop_threshold]\n","df_remained=df[df['percent_remained']>=drop_threshold]\n","print('Number of dropped data points:',len(dropped))\n","#save data\n","dropped.to_csv(os.path.join(path,\"dropped_non_English.csv\"))\n","df_remained.to_csv(os.path.join(path,\"df_remained.csv\"))\n","df_remained.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AvGIcE65t0hO"},"outputs":[],"source":["print(\"remaining data points: \",len(df_remained))\n","df_dropped=df_remained.drop('percent_remained',axis=1)\n","df_train,df_test=(df_dropped.iloc[:-10000],df_dropped.iloc[-10000:])\n","print(len(df_train),len(df_test))\n","df_train.to_csv(os.path.join(path,\"df_train.csv\"))\n","df_test.to_csv(os.path.join(path,\"df_test.csv\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LjQWTM24AP6g"},"outputs":[],"source":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13 (default, Oct  4 2022, 14:00:32) \n[GCC 9.4.0]"},"vscode":{"interpreter":{"hash":"9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"}}},"nbformat":4,"nbformat_minor":0}
