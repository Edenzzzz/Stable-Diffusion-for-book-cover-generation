{"cells":[{"cell_type":"markdown","metadata":{"id":"4Q_h9epMtVKw"},"source":["# 🌟Data preprocessing for Stable Diffusion book cover generation training🌟"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3195,"status":"ok","timestamp":1668962796727,"user":{"displayName":"Eden Tan","userId":"11491147198112718283"},"user_tz":360},"id":"rwI4ZieYtVKy","outputId":"410b59d2-6c1d-42ba-c6d3-ee34242a95b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import cv2,jpeg4py \n","import os\n","import matplotlib.pyplot as plt\n","try:\n","  from google.colab import drive\n","  drive.mount(\"/content/drive\",force_remount=True)\n","except:\n","  pass\n","# path='/Users/eden/Downloads/book dataset'\n","path=\"/content/drive/MyDrive/book dataset\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12172,"status":"ok","timestamp":1668963728855,"user":{"displayName":"Eden Tan","userId":"11491147198112718283"},"user_tz":360},"id":"4l3cluo1mQek","outputId":"8ee16d54-188b-47bb-d05a-c417434ccbb6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Testing df_train.csv\n","len(null_list):0,null_list=[]\n","------------------------------------------------------------------------------------------\n","Testing df_test.csv\n","len(null_list):0,null_list=[]\n","------------------------------------------------------------------------------------------\n"]}],"source":["#@title Test whether all test/train images can be read\n","import glob,os,pandas as pd\n","df_names=[\"df_train.csv\",\"df_test.csv\"]\n","for name in df_names:\n","  print(f\"Testing {name}\")\n","  df=pd.read_csv(f\"/content/drive/MyDrive/book dataset/{name}\")\n","  df.head() \n","  null_list=[] \n","  good_list=[]\n","  for index in df[df.columns[0]]:\n","    try:\n","      file=str(index)+\".jpg\"\n","      os.path.isfile(os.path.join(path+\"/images/images/\",file))\n","      good_list.append(file)\n","    except:\n","      null_list.append(file)\n","  print(f\"len(null_list):{len(null_list)},null_list={null_list}\")\n","  print(\"------------------------------------------------------------------------------------------\")\n"]},{"cell_type":"markdown","metadata":{"id":"WpIpcnsItVKy"},"source":["## 1.Finding a proper(mean) size to resize all images to.\n","I expect this to minimize quality loss due to resizing interpolation(bilinear, bicubic, etc.)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EdaHVWt1tVKz","outputId":"19105bce-7e7a-4916-8208-bccef9f73761"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-8edfa0eb5fa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msub_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mheights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mwidths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["heights=[]\n","widths=[]\n","#path of dataset on my local computer\n","img_path=path+\"/images/images\"\n","\n","df=pd.read_csv(os.path.join(path,\"book_data.csv\"))\n","num_failed=0\n","failed_indices=[]\n","num_images_before=len(df)\n","num_deleted=158\n","#\n","# import sys\n","# raw_stream=sys.stdout\n","# sys.stdout=open('opencv_error.txt','wb')\n","for index in range(len(df)):\n","    sub_path=os.path.join(img_path,str(index)+'.jpg')\n","    try:\n","        img=cv2.imread(sub_path)\n","        heights.append(img.shape[0])\n","        widths.append(img.shape[1])\n","    except AttributeError:\n","        failed_indices.append(index)\n","        df.drop(index,axis=0,inplace=True)\n","        num_failed+=1\n","# sys.stdout=raw_stream#restore\n","\n","print(\"Successfully read {} images\".format(len(heights)),\", failed to read {} images\".format(num_failed))\n","# print(f'Number of images before deleting failed images:{num_images_before}\\\n","#     \\nNumber of images after { len(os.listdir(img_path)) } ')\n","\n","\n","fig,axes=plt.subplots(1,2,figsize=(10,5))\n","\n","#plot 1\n","axes[0].set(xlabel='Height')\n","axes[0].hist(heights); axes[0].set(title='Distribution of image heights')\n","#draw vertical line\n","axes[0].axvline(np.mean(heights), color='orange', linestyle='dashed', linewidth=1)\n","axes[0].text(np.mean(heights)*1.1, axes[0].get_ylim()[1]*0.9, 'Mean: {:.2f}'.format(np.mean(heights)))\n","\n","#plot 2\n","axes[1].set(xlabel='Width')\n","axes[1].hist(widths); axes[1].set(title='Distribution of image widths')\n","axes[1].axvline(np.mean(widths), color='orange', linestyle='--', linewidth=1)\n","axes[1].text(np.mean(widths)*1.1, axes[1].get_ylim()[1]*0.9, 'Mean: {:.2f}'.format(np.mean(widths)))\n","plt.show()\n","\n","print(\"Failed images: \",failed_indices)"]},{"cell_type":"markdown","metadata":{"id":"Y-PYeUPgfUpE"},"source":["### Save data as numpy array for faster loading (will terminate the session at the end)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XkrsfiWRIdGr"},"outputs":[],"source":["# try:\n","#   from google.colab import runtime\n","#   import matplotlib.pyplot as plt\n","#   import tqdm\n","#   num_images_before=54301\n","#   size=256\n","#   stacked_images=np.zeros((num_images_before,size,size,3),dtype=\"float16\")#save memeory. The runtime crashes with float32\n","#   img_path=path+\"/images/images\"\n","\n","#   for index,file in enumerate(tqdm.tqdm(os.listdir(img_path))):\n","#     img=cv2.imread(os.path.join(img_path,file))\n","#     img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","#     img=cv2.resize(img,(size,size),interpolation=cv2.INTER_CUBIC).astype('float16')\n","#     if index%1000==0:\n","#       plt.title(str(index)+\" images processed!\")\n","#       plt.imshow(img.astype(\"int16\"))\n","#       # plt.show()\n","#     #this index has to correspond to the index in the csv file\n","#     try:\n","#       stacked_images[int(file.replace('.jpg','')),:,:,:]=img\n","#     except ValueError:\n","#       pass\n","      \n","#   np.save(os.path.join(path,\"stacked_images.npy\"),stacked_images)\n","#   assert os.path.isfile(os.path.join(path,\"stacked_images.npy\")), \"File not saved!\"\n","\n","#   runtime.unassign()#exit\n","# except:\n","#   pass"]},{"cell_type":"markdown","metadata":{"id":"_1VP23hRtVK0"},"source":["## 2. Preprocess text data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TVAKzu2tVK0"},"outputs":[],"source":["df=pd.read_csv(os.path.join(path,\"book_data.csv\"))\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"YA5e6M4TtVK0"},"source":["### 2.1 Remove entries whose corresponding image can't be read"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GUiVnj9gtVK1"},"outputs":[],"source":["len_before=len(df)\n","df.drop(failed_indices,inplace=True)\n","# df.drop(0,axis=0,inplace=True)\n","if len_before-len(failed_indices)==len(df):\n","    print(f\"Successfully dropped {len(failed_indices)} images!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QV-yy-HItVK1"},"outputs":[],"source":["#Only use 3 features \n","df=df[['book_authors',\"book_desc\",\"book_title\"]]\n","print(\"Number of NaN/None entries\\n:\",df.isna().sum(axis=0),\"\\n--------------------------------------\")\n","# print(\"First 3 null entries:\\n\",df[df['book_desc'].isnull()].iloc[:3])#isnull treats empty String as non-NaN.\n","df.dropna(axis=0,inplace=True)\n","print(\"Number of NaN/None entries after processing \\n \",df.isna().sum())\n","# print(df[df.isna()])#isna() is True for empty String''\n","# df.loc[94]\n","# df.head() "]},{"cell_type":"markdown","metadata":{"id":"0SioNJzntVK1"},"source":["### 2.2. Remove rows with non-English book description"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3JujC6y-tVK1"},"outputs":[],"source":["import re\n","non_English_sentence=\"34歳無職童貞のニートは無一文で家を追い出され、自分の人生が完全に詰んでいたと気付く。己を後悔していた矢先、彼はトラックに轢かれ呆気なく死んでしまう。ついで目を覚ました場所は――なんと剣と魔法の異世界だった!!ルーデウスと名付けられた赤ん坊として生まれ変わった彼は、「今度こそ本気で生きて行くんだ……！」と後悔しない人生を送ると決意する。前世の知能を活かしたルーデウスは瞬く間に魔術の才能を開花させ、小さな女の子の家庭教師をつけてもらうことに。さらにはエメラルドグリーンの髪を持つ美しいクォーターエルフとの出会い。彼の新たな人生が動き始める。――憧れの人生やり直し型転生ファンタジー、ここに始動！\"\n","sentence=\"Despite the tumor-shrinking medical miracle that has bought her a few years, Hazel has never been anything but terminal, her final chapter inscribed upon diagnosis. But when a gorgeous plot twist named Augustus Waters suddenly appears at Cancer Kid Support Group, Hazel's story is about to be completely rewritten.Insightful, bold, irreverent, and raw, The Fault in Our Stars is award-winning author John Green's most ambitious and heartbreaking work yet, brilliantly exploring the funny, thrilling, and tragic business of being alive and in love.\"\n","filter=re.compile('[^A-Za-z0-9.,\\/#!$%\\^\\;:{}=\\-_`~()\\'\\\" ]*')\n","def remained_percent(sentence):\n","    \"\"\"Return how much percentage of the text is filtered out\n","    by the regex matching English words and punctuations\"\"\"\n","    sub=filter.sub(repl=\"\",string=sentence)\n","\n","    return len(sub)/len(sentence)\n","print(\"non-English:\",remained_percent(non_English_sentence))\n","print('English',remained_percent(sentence))\n","# re.sub(pattern=r\"\"\"<\\|startoftext\\|>|<\\|endoftext\\|>|'s|'t|'re|'ve|'m|'ll|'d|[\\p{L}]+|[\\p{N}]|[^\\s\\p{L}\\p{N}]+\"\"\",repl='',string=sentence)"]},{"cell_type":"markdown","metadata":{"id":"ZVuTdJvatVK2"},"source":["### 2.3 Drop non-English-like data points according to threshold and save two subsets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8yYnQKYftVK2"},"outputs":[],"source":["#Apply over the whole dataframe\n","drop_threshold=0.97\n","\n","df['percent_remained']=df['book_desc'].apply(remained_percent)\n","print(\"Mean percentage remained after applying filter:\",df['percent_remained'].mean())\n","dropped=df[df['percent_remained']<drop_threshold]\n","df_remained=df[df['percent_remained']>=drop_threshold]\n","print('Number of dropped data points:',len(dropped))\n","#save data\n","dropped.to_csv(os.path.join(path,\"dropped_non_English.csv\"))\n","df_remained.to_csv(os.path.join(path,\"df_remained.csv\"))\n","df_remained.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AvGIcE65t0hO"},"outputs":[],"source":["print(\"remaining data points: \",len(df_remained))\n","df_dropped=df_remained.drop('percent_remained',axis=1)\n","df_train,df_test=(df_dropped.iloc[:-10000],df_dropped.iloc[-10000:])\n","print(len(df_train),len(df_test))\n","df_train.to_csv(os.path.join(path,\"df_train.csv\"))\n","df_test.to_csv(os.path.join(path,\"df_test.csv\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LjQWTM24AP6g"},"outputs":[],"source":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13 (default, Oct  4 2022, 14:00:32) \n[GCC 9.4.0]"},"vscode":{"interpreter":{"hash":"9ac03a0a6051494cc606d484d27d20fce22fb7b4d169f583271e11d5ba46a56e"}}},"nbformat":4,"nbformat_minor":0}
