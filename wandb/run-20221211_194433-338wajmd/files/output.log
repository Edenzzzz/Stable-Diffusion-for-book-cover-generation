You have passed `None` for safety_checker to disable its functionality in <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'>. Note that this might lead to problems when using <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> and is not recommended.
You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .
Traceback (most recent call last):
  File "/home/wenxuan/.conda/envs/tf1/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/wenxuan/.conda/envs/tf1/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/wenxuan/Stable-diffusion-for-book-cover-generation/sd-inference.py", line 413, in <module>
    ).to(args.device)
  File "/home/wenxuan/.conda/envs/tf1/lib/python3.7/site-packages/diffusers/pipeline_utils.py", line 220, in to
    module.to(torch_device)
  File "/home/wenxuan/.conda/envs/tf1/lib/python3.7/site-packages/torch/nn/modules/module.py", line 927, in to
    return self._apply(convert)
  File "/home/wenxuan/.conda/envs/tf1/lib/python3.7/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/wenxuan/.conda/envs/tf1/lib/python3.7/site-packages/torch/nn/modules/module.py", line 579, in _apply
    module._apply(fn)
  File "/home/wenxuan/.conda/envs/tf1/lib/python3.7/site-packages/torch/nn/modules/module.py", line 602, in _apply
    param_applied = fn(param)
  File "/home/wenxuan/.conda/envs/tf1/lib/python3.7/site-packages/torch/nn/modules/module.py", line 925, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/home/wenxuan/.conda/envs/tf1/lib/python3.7/site-packages/torch/cuda/__init__.py", line 211, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled