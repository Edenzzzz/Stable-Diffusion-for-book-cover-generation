lr after hyperparam["scale_lr"]: 5e-06
Train unet:False || Train text_encoder:True
optimizer after wrapping using accelerator: AcceleratedOptimizer (
Parameter Group 0
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 5e-06
    lr: 5e-06
    weight_decay: 0.01
)
num_update_steps_per_epoch: 625
num_train_epochs 12
accelerator.num_processes 1
Number of training examples: 10000
Train!


























































































































































































































































































































Max gradient update steps:   2%|‚ñè      | 155/7500 [10:36<8:28:50,  4.16s/it, epoch=0, loss=0.00522, step=2494/10000]



Max gradient update steps:   2%|‚ñè         | 156/7500 [10:37<8:28:26,  4.15s/it, epoch=0, loss=0.21, step=2498/10000][34m[1mwandb[39m[22m: Adding directory to artifact (./model_ckpt)... Done. 5.3s
























































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Max gradient update steps:  17%|‚ñä    | 1250/7500 [1:26:52<7:15:57,  4.19s/it, epoch=1, loss=0.0578, step=9999/10000]Traceback (most recent call last):
  File "/usr/lib/python3.8/runpy.py", line 185, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File "/usr/lib/python3.8/runpy.py", line 111, in _get_module_details
    __import__(pkg_name)
  File "/home/wenxuan/Stable-diffusion-for-book-cover-generation/training.py", line 711, in <module>
    notebook_launcher(training_function, args=(
  File "/home/wenxuan/sd_training/lib/python3.8/site-packages/accelerate/launchers.py", line 135, in notebook_launcher
    function(*args)
  File "/home/wenxuan/Stable-diffusion-for-book-cover-generation/training.py", line 706, in training_function
    wandb.run.log_artifact(artifact)
  File "/home/wenxuan/sd_training/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 255, in wrapper
    return func(self, *args, **kwargs)
  File "/home/wenxuan/sd_training/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 2704, in log_artifact
    return self._log_artifact(
  File "/home/wenxuan/sd_training/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 2841, in _log_artifact
    self._assert_can_log_artifact(artifact)
  File "/home/wenxuan/sd_training/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 2889, in _assert_can_log_artifact
    artifact.name,
  File "/home/wenxuan/sd_training/lib/python3.8/site-packages/wandb/sdk/wandb_artifacts.py", line 260, in name
    return self._logged_artifact.name
  File "/home/wenxuan/sd_training/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 3704, in name
    return self._assert_instance().name
  File "/home/wenxuan/sd_training/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 3667, in _assert_instance
    raise ValueError(
ValueError: Must call wait() before accessing logged artifact properties